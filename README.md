# ğŸ“Š TPS Data Architecture

Architecture data en 4 couches pour centraliser et analyser les donnÃ©es comptables de 3500+ dossiers clients.

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![MySQL](https://img.shields.io/badge/MySQL-8.0%2B-blue.svg)](https://www.mysql.com/)
[![Bash](https://img.shields.io/badge/Bash-5.0%2B-green.svg)](https://www.gnu.org/software/bash/)

---

## ğŸ¯ Vue d'ensemble

Pipeline ETL 4 couches pour centraliser les donnÃ©es de 3500+ dossiers comptables depuis ACD, Pennylane et DIA Valoxy.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAW (copies brutes)                   ğŸ”§ EN COURS          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”œâ”€â”€ raw_dia         : DonnÃ©es cabinet (temps, exercices)  â”‚
â”‚  â”œâ”€â”€ raw_acd         : 6 tables centralisÃ©es (3500 bases)  â”‚
â”‚  â””â”€â”€ raw_pennylane   : Export Redshift                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRANSFORM (normalisation)             âš ï¸ NE PAS MODIFIER   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â””â”€â”€ transform_compta                                       â”‚
â”‚       â”œâ”€â”€ dossiers_acd, dossiers_pennylane                 â”‚
â”‚       â”œâ”€â”€ ecritures_mensuelles (C*/F* agrÃ©gÃ©s)             â”‚
â”‚       â”œâ”€â”€ ecritures_tiers_detaillees (401/411)             â”‚
â”‚       â””â”€â”€ exercices, temps_collaborateurs                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MDM (rÃ©fÃ©rentiel maÃ®tre)              âš ï¸ NE PAS MODIFIER   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â””â”€â”€ mdm                                                    â”‚
â”‚       â”œâ”€â”€ dossiers (jointure SIREN)                        â”‚
â”‚       â”œâ”€â”€ collaborateurs, contacts                         â”‚
â”‚       â””â”€â”€ mapping_comptes_services                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MART (vues mÃ©tier)                    âš ï¸ NE PAS MODIFIER   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”œâ”€â”€ mart_pilotage_cabinet    : Directeurs, comptables    â”‚
â”‚  â”œâ”€â”€ mart_controle_gestion    : ContrÃ´leurs de gestion    â”‚
â”‚  â””â”€â”€ mart_production_client   : Clients (holdings)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sources de donnÃ©es

- **ACD/DIA** : 3500+ bases MySQL `compta_*` (serveur distant)
- **Pennylane** : Export Redshift (nouveau logiciel comptable)
- **DIA Valoxy** : Base locale pour donnÃ©es cabinet

---

## âš ï¸ RÃ¨gle importante

**â›” NE PAS TOUCHER AUX COUCHES TRANSFORM / MDM / MART**

Actuellement en phase de **validation de la couche RAW** :
- Import ACD centralisÃ© (raw_acd) en cours de test
- Import Pennylane en cours de validation
- Les couches supÃ©rieures ne doivent pas Ãªtre modifiÃ©es tant que RAW n'est pas stable

---

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

```bash
# MySQL 8.0+
mysql --version

# Bash 5.0+
bash --version

# Outils requis
which mysqldump
which xargs
```

### Configuration

1. **Copier le fichier de configuration :**

```bash
cp bash/config.sh.example bash/config.sh
```

2. **Ã‰diter bash/config.sh avec vos credentials :**

```bash
# Connexion ACD (serveur distant)
ACD_HOST="<IP_SERVEUR>"
ACD_PORT=3306
ACD_USER="<USER>"
ACD_PASS="<PASSWORD>"

# Connexion MySQL locale
LOCAL_USER="root"
LOCAL_PASS="<PASSWORD>"
```

âš ï¸ **Ce fichier est dans .gitignore** (ne jamais le commiter)

### Installation

```bash
# 1. CrÃ©er les schÃ©mas et tables
./run_pipeline.sh --init-only

# 2. Importer les donnÃ©es RAW (premiÃ¨re fois)
./run_pipeline.sh --data-only --acd-full

# 3. VÃ©rifier l'import
mysql -u root -p -e "SELECT COUNT(DISTINCT dossier_code) FROM raw_acd.histo_ligne_ecriture"
```

---

## ğŸ“š Documentation

- **[COMMANDS.md](COMMANDS.md)** - Guide complet de toutes les commandes
- **[README_raw_acd.md](README_raw_acd.md)** - Documentation dÃ©taillÃ©e de l'import ACD
- **[claude.md](claude.md)** - Documentation projet et vision stratÃ©gique

---

## ğŸ”§ Commandes principales

### Import RAW complet

```bash
# Import full (TRUNCATE + rÃ©import 3500 bases)
./run_pipeline.sh --acd-full
# DurÃ©e: ~60-90 minutes

# Import incrÃ©mental (nouveautÃ©s uniquement)
./run_pipeline.sh --acd-incremental
# DurÃ©e: ~20-30 minutes
```

### Import RAW uniquement (sans TRANSFORM/MDM/MART)

```bash
# Import RAW avec ACD full
./run_pipeline.sh --data-only --acd-full

# Import RAW avec ACD incrÃ©mental
./run_pipeline.sh --data-only --acd-incremental
```

### Import ACD spÃ©cifique

```bash
# Import complet (TRUNCATE + 3500 bases)
bash bash/raw/02_import_raw_compta.sh --full

# Import incrÃ©mental (depuis last_sync_date)
bash bash/raw/02_import_raw_compta.sh --incremental

# Import depuis une date spÃ©cifique
bash bash/raw/02_import_raw_compta.sh --since "01/01/2025 00:00:00"
```

### Nettoyage

```bash
# Supprimer TOUTES les bases
bash bash/util/clean_all.sh

# Vider uniquement raw_acd
bash bash/raw/02c_cleanup_acd.sh --full

# Afficher les statistiques
bash bash/raw/02c_cleanup_acd.sh --stats
```

### Benchmark

```bash
# Tester les performances d'import sur 10 bases
bash bash/util/benchmark_import_acd.sh
```

**RÃ©sultat** : âœ… MÃ©thode 1 (INSERT SELECT sans batching) est la plus rapide - **implÃ©mentÃ©e dans le script actuel**

---

## ğŸ“ Structure du projet

```
tps_get_data/
â”œâ”€â”€ run_pipeline.sh              # ğŸ¯ Orchestrateur principal
â”œâ”€â”€ bash/
â”‚   â”œâ”€â”€ config.sh                # Configuration (gitignored)
â”‚   â”œâ”€â”€ logging.sh               # Fonctions log uniformes
â”‚   â”œâ”€â”€ raw/                     # ğŸ”§ Scripts d'import RAW (FOCUS ACTUEL)
â”‚   â”‚   â”œâ”€â”€ 01_import_raw_dia.sh
â”‚   â”‚   â”œâ”€â”€ 02_import_raw_compta.sh       # Import ACD centralisÃ© â­
â”‚   â”‚   â”œâ”€â”€ 02b_import_incremental_acd.sh
â”‚   â”‚   â”œâ”€â”€ 02c_cleanup_acd.sh
â”‚   â”‚   â”œâ”€â”€ 03_import_raw_pennylane.sh
â”‚   â”‚   â”œâ”€â”€ 03b_cleanup_pennylane.sh
â”‚   â”‚   â””â”€â”€ run_all_raw.sh
â”‚   â”œâ”€â”€ transform/               # âš ï¸ NE PAS MODIFIER
â”‚   â”œâ”€â”€ mdm/                     # âš ï¸ NE PAS MODIFIER
â”‚   â”œâ”€â”€ mart/                    # âš ï¸ NE PAS MODIFIER
â”‚   â””â”€â”€ util/
â”‚       â”œâ”€â”€ clean_all.sh         # Suppression complÃ¨te
â”‚       â””â”€â”€ benchmark_import_acd.sh  # Benchmark performance
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_create_schemas.sql
â”‚   â”œâ”€â”€ 02b_raw_acd_tables.sql   # Tables raw_acd (partitionnement) â­
â”‚   â”œâ”€â”€ 02_raw_pennylane_tables.sql
â”‚   â”œâ”€â”€ 03_transform_tables.sql  # âš ï¸ NE PAS MODIFIER
â”‚   â”œâ”€â”€ 04_mdm_tables.sql        # âš ï¸ NE PAS MODIFIER
â”‚   â”œâ”€â”€ 05_mart_views.sql        # âš ï¸ NE PAS MODIFIER
â”‚   â””â”€â”€ 06-08_procedures_*.sql   # âš ï¸ NE PAS MODIFIER
â”œâ”€â”€ logs/                        # Logs des exÃ©cutions
â”œâ”€â”€ COMMANDS.md                  # Guide des commandes
â”œâ”€â”€ README_raw_acd.md            # Doc import ACD
â””â”€â”€ claude.md                    # Doc projet complÃ¨te
```

---

## ğŸ” RequÃªtes utiles

### Statistiques raw_acd

```sql
-- Derniers imports
SELECT * FROM raw_acd.sync_tracking;

-- Nombre de dossiers centralisÃ©s
SELECT COUNT(DISTINCT dossier_code) FROM raw_acd.histo_ligne_ecriture;

-- VolumÃ©trie par table
SELECT
    table_name,
    FORMAT(rows_count, 0) as nb_lignes,
    last_sync_type as mode,
    DATE_FORMAT(last_sync_date, '%Y-%m-%d %H:%i') as derniere_synchro
FROM raw_acd.sync_tracking
ORDER BY table_name;

-- Taille des donnÃ©es
SELECT
    table_name,
    CONCAT(ROUND(data_length / 1024 / 1024, 2), ' MB') AS donnees,
    CONCAT(ROUND(index_length / 1024 / 1024, 2), ' MB') AS index,
    CONCAT(ROUND((data_length + index_length) / 1024 / 1024, 2), ' MB') AS total
FROM information_schema.tables
WHERE table_schema = 'raw_acd'
ORDER BY (data_length + index_length) DESC;
```

### VÃ©rifier la qualitÃ© des donnÃ©es

```sql
-- Dossiers avec le plus d'Ã©critures
SELECT
    dossier_code,
    COUNT(*) as nb_ecritures
FROM raw_acd.histo_ligne_ecriture
GROUP BY dossier_code
ORDER BY nb_ecritures DESC
LIMIT 20;

-- Distribution par annÃ©e
SELECT
    HE_ANNEE as annee,
    COUNT(*) as nb_lignes
FROM raw_acd.histo_ligne_ecriture
GROUP BY HE_ANNEE
ORDER BY HE_ANNEE;
```

---

## ğŸ¯ Focus actuel : Couche RAW

### Import ACD centralisÃ© (raw_acd)

**ProblÃ©matique** : 3500 bases `compta_*` avec 50+ tables chacune â†’ stockage Ã©norme

**Solution** : Import sÃ©lectif de 6 tables dans `raw_acd` centralisÃ©e

**Tables importÃ©es** :
1. `histo_ligne_ecriture` - Lignes Ã©critures historiques (partitionnÃ© par annÃ©e)
2. `histo_ecriture` - En-tÃªtes Ã©critures historiques
3. `ligne_ecriture` - Lignes Ã©critures courantes
4. `ecriture` - En-tÃªtes Ã©critures courantes
5. `compte` - Plan comptable
6. `journal` - Journaux

**MÃ©canisme** :
- Mode `--full` : TRUNCATE + rÃ©import complet
- Mode `--incremental` : Import avec filtre `WHERE date > last_sync_date` + `ON DUPLICATE KEY UPDATE`
- Tracking via `sync_tracking` (last_sync_date, rows_count, duration)

**Performance** :
- Import sÃ©quentiel (source ACD 1 CPU - pas de parallÃ©lisme)
- Compression MySQL : `--compress`
- **âš¡ OptimisÃ©** : MÃ©thode 1 du benchmark (INSERT SELECT sans batching)
- **âš¡ last_sync_date** : rÃ©cupÃ©rÃ© 1x au lieu de 3500x en mode incrÃ©mental
- Estimation : ~4-6h pour 3500 bases

---

## âš¡ Automatisation (cron)

### Import quotidien Ã  2h00

```cron
0 2 * * * cd /path/to/tps_get_data && ./run_pipeline.sh --acd-incremental 2>&1 | logger -t data_pipeline
```

### Import complet hebdomadaire (dimanche 1h00)

```cron
0 1 * * 0 cd /path/to/tps_get_data && ./run_pipeline.sh --acd-full 2>&1 | logger -t data_pipeline
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : Connexion ACD Ã©choue

```bash
# Tester la connexion
mysql -h <ACD_HOST> -P <ACD_PORT> -u <ACD_USER> -p<ACD_PASS> -e "SELECT 1"
```

### ProblÃ¨me : Import trÃ¨s lent

```bash
# VÃ©rifier le nombre de bases Ã  traiter
mysql -h <ACD_HOST> -u <ACD_USER> -p -e "
    SELECT COUNT(*) FROM information_schema.schemata
    WHERE schema_name LIKE 'compta_%'
"

# Lancer le benchmark pour comparer les mÃ©thodes
bash bash/util/benchmark_import_acd.sh
```

### ProblÃ¨me : DonnÃ©es manquantes

```bash
# VÃ©rifier sync_tracking
mysql -u root -p raw_acd -e "SELECT * FROM sync_tracking"

# Relancer import complet
bash bash/raw/02_import_raw_compta.sh --full
```

---

## ğŸ“Š Logs

Les logs sont disponibles dans :
```
logs/pipeline_YYYYMMDD_HHMMSS.log
```

Rotation automatique : conservation de 30 jours

---

## ğŸ¯ Roadmap

### Phase 1 : Stabilisation RAW (EN COURS)
- âœ… Import ACD centralisÃ© (raw_acd)
- âœ… Optimisation performances (benchmark MÃ©thode 1 appliquÃ©)
- ğŸ”„ Validation import incrÃ©mental en production
- â³ Tests sur 3500 bases

### Phase 2 : Adaptation TRANSFORM
1. Adapter les procÃ©dures pour utiliser raw_acd
2. Tester les agrÃ©gations ecritures_mensuelles
3. Valider la qualitÃ© des donnÃ©es transformÃ©es

### Phase 3 : Enrichissement MDM
1. DÃ©duplication SIREN
2. Jointure multi-sources (ACD â†” Pennylane â†” Silae)
3. API backend pour synchronisation

### Phase 4 : Vues MART par profil utilisateur
- MART Comptables (directeurs, comptables)
- MART ContrÃ´le de gestion (interne/externe)
- MART Production client (holdings)

---

## ğŸ“ Support

- **Documentation** : Voir [COMMANDS.md](COMMANDS.md) et [README_raw_acd.md](README_raw_acd.md)
- **Logs** : `logs/pipeline_YYYYMMDD_HHMMSS.log`
- **Issues** : [GitHub Issues](https://github.com/jharjharbink/tps_get_data/issues)

---

## ğŸ“ License

MIT License - voir [LICENSE](LICENSE) pour plus de dÃ©tails

---

**âš ï¸ Focus actuel : VALIDATION DE LA COUCHE RAW UNIQUEMENT**
